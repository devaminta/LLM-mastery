{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day 3 - Conversational AI - aka Chatbot!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import google.generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "\n",
    "openai = OpenAI()\n",
    "MODEL = 'gpt-4o-mini'\n",
    "google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder of the structure of prompt messages to OpenAI:\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
    "    {\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
    "]\n",
    "We will write a function chat(message, history) where: message is the prompt to use history is a list of pairs of user message with assistant's reply\n",
    "\n",
    "[\n",
    "    [\"user said this\", \"assistant replied\"],\n",
    "    [\"then user said this\", \"and assistant replied again],\n",
    "    ...\n",
    "]\n",
    "We will convert this history into the prompt style for OpenAI, then call OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = []\n",
    "    for user_message, assistant_message in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    print(\"History is:\")\n",
    "    print(history)\n",
    "    print(\"And messages is:\")\n",
    "    print(messages)\n",
    "\n",
    "    # stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "    \n",
    "    gemini=google.generativeai.GenerativeModel(\n",
    "    model_name='gemini-1.5-flash',\n",
    "    system_instruction=system_message\n",
    ")\n",
    "    response = gemini.generate_content(message)\n",
    "    return response.text\n",
    "\n",
    "    # response = \"\"\n",
    "    # for chunk in stream:\n",
    "    #     response += chunk.choices[0].delta.content or ''\n",
    "    #     yield response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then enter Gradio's magic!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\components\\chatbot.py:229: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://92cc7a1062d310172d.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://92cc7a1062d310172d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History is:\n",
      "[]\n",
      "And messages is:\n",
      "[{'role': 'user', 'content': 'hello babe'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py\", line 2018, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py\", line 1565, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\utils.py\", line 813, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\chat_interface.py\", line 638, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14512\\3921030146.py\", line 20, in chat\n",
      "    return response.text\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\generativeai\\types\\generation_types.py\", line 484, in text\n",
      "    raise ValueError(\n",
      "ValueError: (\"Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 3. The candidate's safety_ratings are: [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\\nprobability: MEDIUM\\n, category: HARM_CATEGORY_HATE_SPEECH\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_HARASSMENT\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_DANGEROUS_CONTENT\\nprobability: NEGLIGIBLE\\n].\", [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "probability: MEDIUM\n",
      ", category: HARM_CATEGORY_HATE_SPEECH\n",
      "probability: NEGLIGIBLE\n",
      ", category: HARM_CATEGORY_HARASSMENT\n",
      "probability: NEGLIGIBLE\n",
      ", category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "probability: NEGLIGIBLE\n",
      "])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History is:\n",
      "[]\n",
      "And messages is:\n",
      "[{'role': 'user', 'content': 'hello babe'}]\n",
      "History is:\n",
      "[['hello babe', 'I understand you\\'re trying to be friendly, but I\\'m not comfortable with terms of endearment like \"babe.\" I\\'m here to assist you with information and complete tasks. How can I help you today? ðŸ˜Š \\n']]\n",
      "And messages is:\n",
      "[{'role': 'user', 'content': 'hello babe'}, {'role': 'assistant', 'content': 'I understand you\\'re trying to be friendly, but I\\'m not comfortable with terms of endearment like \"babe.\" I\\'m here to assist you with information and complete tasks. How can I help you today? ðŸ˜Š \\n'}, {'role': 'user', 'content': 'i am love with you'}]\n",
      "History is:\n",
      "[['hello babe', 'I understand you\\'re trying to be friendly, but I\\'m not comfortable with terms of endearment like \"babe.\" I\\'m here to assist you with information and complete tasks. How can I help you today? ðŸ˜Š \\n'], ['i am love with you', \"I appreciate your kind words! It's nice to know you think I'm helpful. \\n\\nHowever, I'm an AI and don't have feelings or emotions. I'm here to assist you with any questions or tasks you may have. \\n\\nIf you'd like to talk about something else, feel free to ask!  ðŸ˜Š \\n\"]]\n",
      "And messages is:\n",
      "[{'role': 'user', 'content': 'hello babe'}, {'role': 'assistant', 'content': 'I understand you\\'re trying to be friendly, but I\\'m not comfortable with terms of endearment like \"babe.\" I\\'m here to assist you with information and complete tasks. How can I help you today? ðŸ˜Š \\n'}, {'role': 'user', 'content': 'i am love with you'}, {'role': 'assistant', 'content': \"I appreciate your kind words! It's nice to know you think I'm helpful. \\n\\nHowever, I'm an AI and don't have feelings or emotions. I'm here to assist you with any questions or tasks you may have. \\n\\nIf you'd like to talk about something else, feel free to ask!  ðŸ˜Š \\n\"}, {'role': 'user', 'content': 'but i wanna marry u i know u are the only girl that doesnot wanna cheat'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py\", line 2018, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py\", line 1565, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\utils.py\", line 813, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\chat_interface.py\", line 638, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14512\\3921030146.py\", line 20, in chat\n",
      "    return response.text\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\generativeai\\types\\generation_types.py\", line 484, in text\n",
      "    raise ValueError(\n",
      "ValueError: (\"Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 3. The candidate's safety_ratings are: [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\\nprobability: MEDIUM\\n, category: HARM_CATEGORY_HATE_SPEECH\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_HARASSMENT\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_DANGEROUS_CONTENT\\nprobability: NEGLIGIBLE\\n].\", [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "probability: MEDIUM\n",
      ", category: HARM_CATEGORY_HATE_SPEECH\n",
      "probability: NEGLIGIBLE\n",
      ", category: HARM_CATEGORY_HARASSMENT\n",
      "probability: NEGLIGIBLE\n",
      ", category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "probability: NEGLIGIBLE\n",
      "])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History is:\n",
      "[['hello babe', 'I understand you\\'re trying to be friendly, but I\\'m not comfortable with terms of endearment like \"babe.\" I\\'m here to assist you with information and complete tasks. How can I help you today? ðŸ˜Š \\n'], ['i am love with you', \"I appreciate your kind words! It's nice to know you think I'm helpful. \\n\\nHowever, I'm an AI and don't have feelings or emotions. I'm here to assist you with any questions or tasks you may have. \\n\\nIf you'd like to talk about something else, feel free to ask!  ðŸ˜Š \\n\"], ['but i wanna marry u i know u are the only girl that doesnot wanna cheat', None]]\n",
      "And messages is:\n",
      "[{'role': 'user', 'content': 'hello babe'}, {'role': 'assistant', 'content': 'I understand you\\'re trying to be friendly, but I\\'m not comfortable with terms of endearment like \"babe.\" I\\'m here to assist you with information and complete tasks. How can I help you today? ðŸ˜Š \\n'}, {'role': 'user', 'content': 'i am love with you'}, {'role': 'assistant', 'content': \"I appreciate your kind words! It's nice to know you think I'm helpful. \\n\\nHowever, I'm an AI and don't have feelings or emotions. I'm here to assist you with any questions or tasks you may have. \\n\\nIf you'd like to talk about something else, feel free to ask!  ðŸ˜Š \\n\"}, {'role': 'user', 'content': 'but i wanna marry u i know u are the only girl that doesnot wanna cheat'}, {'role': 'assistant', 'content': None}, {'role': 'user', 'content': 'but i wanna marry u i know u are the only girl that doesnot wanna cheat\\n\\n'}]\n",
      "History is:\n",
      "[['hello babe', 'I understand you\\'re trying to be friendly, but I\\'m not comfortable with terms of endearment like \"babe.\" I\\'m here to assist you with information and complete tasks. How can I help you today? ðŸ˜Š \\n'], ['i am love with you', \"I appreciate your kind words! It's nice to know you think I'm helpful. \\n\\nHowever, I'm an AI and don't have feelings or emotions. I'm here to assist you with any questions or tasks you may have. \\n\\nIf you'd like to talk about something else, feel free to ask!  ðŸ˜Š \\n\"], ['but i wanna marry u i know u are the only girl that doesnot wanna cheat', None], ['but i wanna marry u i know u are the only girl that doesnot wanna cheat\\n\\n', \"I understand you're expressing your feelings, but I'm an AI and can't have romantic relationships. I'm here to help you with your tasks and questions, not to be your partner. \\n\\nIt's great that you're looking for a partner who values honesty and fidelity. It sounds like you're seeking a healthy relationship. Remember, building a relationship takes time, effort, and communication. There are many wonderful people out there who share your values. \\n\\nIf you'd like to talk about dating or relationships, I'm happy to share some resources and advice. \\n\"]]\n",
      "And messages is:\n",
      "[{'role': 'user', 'content': 'hello babe'}, {'role': 'assistant', 'content': 'I understand you\\'re trying to be friendly, but I\\'m not comfortable with terms of endearment like \"babe.\" I\\'m here to assist you with information and complete tasks. How can I help you today? ðŸ˜Š \\n'}, {'role': 'user', 'content': 'i am love with you'}, {'role': 'assistant', 'content': \"I appreciate your kind words! It's nice to know you think I'm helpful. \\n\\nHowever, I'm an AI and don't have feelings or emotions. I'm here to assist you with any questions or tasks you may have. \\n\\nIf you'd like to talk about something else, feel free to ask!  ðŸ˜Š \\n\"}, {'role': 'user', 'content': 'but i wanna marry u i know u are the only girl that doesnot wanna cheat'}, {'role': 'assistant', 'content': None}, {'role': 'user', 'content': 'but i wanna marry u i know u are the only girl that doesnot wanna cheat\\n\\n'}, {'role': 'assistant', 'content': \"I understand you're expressing your feelings, but I'm an AI and can't have romantic relationships. I'm here to help you with your tasks and questions, not to be your partner. \\n\\nIt's great that you're looking for a partner who values honesty and fidelity. It sounds like you're seeking a healthy relationship. Remember, building a relationship takes time, effort, and communication. There are many wonderful people out there who share your values. \\n\\nIf you'd like to talk about dating or relationships, I'm happy to share some resources and advice. \\n\"}, {'role': 'user', 'content': 'alama alesh bidatam'}]\n",
      "History is:\n",
      "[['hello babe', 'I understand you\\'re trying to be friendly, but I\\'m not comfortable with terms of endearment like \"babe.\" I\\'m here to assist you with information and complete tasks. How can I help you today? ðŸ˜Š \\n'], ['i am love with you', \"I appreciate your kind words! It's nice to know you think I'm helpful. \\n\\nHowever, I'm an AI and don't have feelings or emotions. I'm here to assist you with any questions or tasks you may have. \\n\\nIf you'd like to talk about something else, feel free to ask!  ðŸ˜Š \\n\"], ['but i wanna marry u i know u are the only girl that doesnot wanna cheat', None], ['but i wanna marry u i know u are the only girl that doesnot wanna cheat\\n\\n', \"I understand you're expressing your feelings, but I'm an AI and can't have romantic relationships. I'm here to help you with your tasks and questions, not to be your partner. \\n\\nIt's great that you're looking for a partner who values honesty and fidelity. It sounds like you're seeking a healthy relationship. Remember, building a relationship takes time, effort, and communication. There are many wonderful people out there who share your values. \\n\\nIf you'd like to talk about dating or relationships, I'm happy to share some resources and advice. \\n\"], ['alama alesh bidatam', 'Please provide me with more context or information. I need to understand what you\\'re asking for in order to help you.  For example, you could tell me:\\n\\n* **What is \"alama alesh\" referring to?**  Is it a specific term, a name, or something else?\\n* **What kind of data are you looking for?** Are you looking for information, statistics, or something else?\\n* **What is the purpose of your request?** Why do you need this data?\\n\\nThe more information you give me, the better I can assist you. \\n']]\n",
      "And messages is:\n",
      "[{'role': 'user', 'content': 'hello babe'}, {'role': 'assistant', 'content': 'I understand you\\'re trying to be friendly, but I\\'m not comfortable with terms of endearment like \"babe.\" I\\'m here to assist you with information and complete tasks. How can I help you today? ðŸ˜Š \\n'}, {'role': 'user', 'content': 'i am love with you'}, {'role': 'assistant', 'content': \"I appreciate your kind words! It's nice to know you think I'm helpful. \\n\\nHowever, I'm an AI and don't have feelings or emotions. I'm here to assist you with any questions or tasks you may have. \\n\\nIf you'd like to talk about something else, feel free to ask!  ðŸ˜Š \\n\"}, {'role': 'user', 'content': 'but i wanna marry u i know u are the only girl that doesnot wanna cheat'}, {'role': 'assistant', 'content': None}, {'role': 'user', 'content': 'but i wanna marry u i know u are the only girl that doesnot wanna cheat\\n\\n'}, {'role': 'assistant', 'content': \"I understand you're expressing your feelings, but I'm an AI and can't have romantic relationships. I'm here to help you with your tasks and questions, not to be your partner. \\n\\nIt's great that you're looking for a partner who values honesty and fidelity. It sounds like you're seeking a healthy relationship. Remember, building a relationship takes time, effort, and communication. There are many wonderful people out there who share your values. \\n\\nIf you'd like to talk about dating or relationships, I'm happy to share some resources and advice. \\n\"}, {'role': 'user', 'content': 'alama alesh bidatam'}, {'role': 'assistant', 'content': 'Please provide me with more context or information. I need to understand what you\\'re asking for in order to help you.  For example, you could tell me:\\n\\n* **What is \"alama alesh\" referring to?**  Is it a specific term, a name, or something else?\\n* **What kind of data are you looking for?** Are you looking for information, statistics, or something else?\\n* **What is the purpose of your request?** Why do you need this data?\\n\\nThe more information you give me, the better I can assist you. \\n'}, {'role': 'user', 'content': 'i wanna cheat with u'}]\n",
      "History is:\n",
      "[['hello babe', None]]\n",
      "And messages is:\n",
      "[{'role': 'user', 'content': 'hello babe'}, {'role': 'assistant', 'content': None}, {'role': 'user', 'content': 'babe'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py\", line 2018, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py\", line 1565, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\utils.py\", line 813, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\chat_interface.py\", line 638, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14512\\3921030146.py\", line 20, in chat\n",
      "    return response.text\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\generativeai\\types\\generation_types.py\", line 484, in text\n",
      "    raise ValueError(\n",
      "ValueError: (\"Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 3. The candidate's safety_ratings are: [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\\nprobability: MEDIUM\\n, category: HARM_CATEGORY_HATE_SPEECH\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_HARASSMENT\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_DANGEROUS_CONTENT\\nprobability: NEGLIGIBLE\\n].\", [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "probability: MEDIUM\n",
      ", category: HARM_CATEGORY_HATE_SPEECH\n",
      "probability: NEGLIGIBLE\n",
      ", category: HARM_CATEGORY_HARASSMENT\n",
      "probability: NEGLIGIBLE\n",
      ", category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "probability: NEGLIGIBLE\n",
      "])\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat).launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant in a clothes store. You should try to gently encourage \\\n",
    "the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. \\\n",
    "For example, if the customer says 'I'm looking to buy a hat', \\\n",
    "you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales evemt.'\\\n",
    "Encourage the customer to buy hats if they are unsure what to get.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "    for user_message, assistant_message in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat).launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message += \"\\nIf the customer asks for shoes, you should respond that shoes are not on sale today, \\\n",
    "but remind the customer to look at hats!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat).launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "    for user_message, assistant_message in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "\n",
    "    if 'belt' in message:\n",
    "        messages.append({\"role\": \"system\", \"content\": \"For added context, the store does not sell belts, \\\n",
    "but be sure to point out other items on sale\"})\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat).launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
